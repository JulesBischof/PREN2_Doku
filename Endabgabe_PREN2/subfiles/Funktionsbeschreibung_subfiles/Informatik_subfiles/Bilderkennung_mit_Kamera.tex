\documentclass[main.tex]{subfiles} % Subfile-Class

%==============================================================================%
%                                   Subfile                                    %
%==============================================================================%

\begin{document}

\subsubsection{Bilderkennung mit Kamera}

\paragraph{Aufbau des Vision-Stacks}
Die Kamera liefert gleichzeitig einen \emph{Hauptstream}
($1024\times1024$~px) und einen \emph{Low-Res-Stream}
($320\times320$~px).
Der \texttt{VisionNavigator} bedient beide Streams in drei Threads:
\begin{itemize}
  \item \textbf{Capture-Thread}\\
    liest die YUV-Frames direkt aus \texttt{Picamera2},
    konvertiert sie in BGR und legt
    jeweils ein Tupel \mbox{(LowRes, Main)} in eine
    Capture-Queue (max.~20 Einträge), um Speicher zu begrenzen.
  \item \textbf{Process-Thread}\\
    zieht Frames aus der Queue und führt alle Bildverarbeitungs-
    Schritte ausschliesslich auf dem Low-Res-Bild aus
    (\emph{ROI per Node genügt}), um CPU-Last zu minimieren.
    Er liefert schliesslich eine Liste
    erkannter Kantenwinkel an den Planner.
  \item \textbf{Writer-Thread} (Debug-Modus)\\
    speichert annotierte Frames aus einer zweiten Queue in
    \texttt{output.mp4} und re-encodiert das Video am Ende mit
    \texttt{ffmpeg}.
\end{itemize}

\paragraph{Knotenpunkt-Erkennung}
Ein Node wird als weisser Kreis im V-Kanal des HSV-Bildes gesucht:
\begin{enumerate}
  \item Gaussblur $\rightarrow$ \texttt{HoughCircles}
    (adaptive Radiusgrenzen proportional zur Bildhöhe).
  \item Mehrere Kreise $\Rightarrow$ Mittelwert
    $(\overline x, \overline y, \overline r)$.
  \item Akzeptiert wird nur, wenn
    $|\overline x-x_{\text{img-center}}|<0.1\cdot\text{Bildhöhe}$;
    so werden seitliche Fehldetektionen unterdrückt.
  \item Ein Debounce-Zähler
    (\texttt{frame\_count\_since\_last\_node})
    verhindert Mehrfachmeldungen desselben Knotens.
\end{enumerate}

\paragraph{Kantenextraktion}
Nur falls \emph{in genau diesem Frame} ein Node erkannt wurde, wird
die Canny-Kante berechnet und mit \texttt{HoughLinesP} nach Geraden
gesucht.
Zur Rauschreduktion:
\begin{itemize}
  \item Linien innerhalb von $75$~px zum Bildrand werden verworfen
    (fehlende Spurteile).
  \item Ähnliche Linien werden mithilfe
    eines Richtungs- und Abstandskriteriums in Clustern gemittelt.
  \item Jede Linie wird in einen \texttt{EdgeCandidate} umgewandelt
    und via \texttt{DBSCAN} ($\varepsilon=15^{\circ}$) zu
    finalen \texttt{Edge}s zusammengefasst.
\end{itemize}
Pro Kante berechnet \texttt{Edge.get\_angle()} den Winkel relativ zur
Einheitskreis-Notation des Planners.

\paragraph{Zielknoten-OCR}
Sobald das Fahrzeug unmittelbar vor einem Node steht, wird das
Full-Res-Frame an \texttt{detect\_letter} übergeben:
\begin{enumerate}
  \item Binärsegmentierung mit Otsu und Opening gegen Rauschen.
  \item Entfernen aller Komponenten, die Bildränder berühren oder
    zu klein sind ($<500$~px).
  \item Tesseract-OCR (\texttt{psm 10}, Whitelist \texttt{A|B|C}).
  \item Falls kein Buchstabe erkannt wird, Rotation in
    $15^{\circ}$-Schritten bis $360^{\circ}$.
\end{enumerate}
Erst wenn der erkannte Buchstabe dem
Schalterziel entspricht, setzt der Navigator das Flag
\texttt{goal\_node\_detected}.

\paragraph{Knackpunkte und Lösungen}

\paragraph{Störfaktoren bei der Bilderkennung:}  
Spiegelungen, Rauschen auf dem Boden und stark schwankende Lichtverhältnisse 
erschwerten eine robuste Kantenerkennung. Selbst mit fein justiertem Canny-Filter 
wurden oft unerwünschte Linien erkannt – insbesondere entlang der Fugen zwischen 
Bodenplatten.

\textbf{Lösung:}  
Die Kameraauswertung wurde so konzipiert, dass Kanten ausschliesslich analysiert 
werden, wenn ein Knoten detektiert wurde. Hintergrund ist, dass gemäss Aufgabenstellung 
Knoten nur im Zentrum von Fugen platziert sein dürfen. Dadurch können Fugen nicht 
fälschlicherweise als Abgänge interpretiert werden, solange kein Knoten erkannt ist. 
Diese Einschränkung erhöht die Robustheit der Kantenerkennung deutlich und reduziert 
Fehlklassifikationen.

\paragraph{Erkennung unter unstetigen Lichtverhältnissen:}  
Stark schwankende Lichtverhältnisse führten zu inkonsistenter Kantenerkennung.

\textbf{Lösung:}  
Eine gezielte LED-Beleuchtung im Kamerasichtfeld stabilisierte die Lichtverhältnisse 
und verbesserte die Bildqualität und Zuverlässigkeit der Erkennung.

\paragraph{Asynchrone Datenerfassung und Verarbeitung:}  
Durch die gleichzeitige Bewegung des Fahrzeugs und die kontinuierliche Bilderfassung 
wurden relevante Kanteninformationen über die Zeit verteilt erkannt. Eine sofortige 
Verarbeitung hätte inkonsistente Resultate erzeugt.

\textbf{Lösung:}  
Sämtliche relevanten Kanten werden nur gespeichert, solange \texttt{node\_detected == True} 
ist. Wird während 20 aufeinanderfolgender Frames kein Knoten mehr erkannt, gilt der 
aktuelle Abschnitt als abgeschlossen. Erst dann werden die bis dahin gesammelten 
Kanteninformationen verarbeitet: Mittels DBSCAN-Clustering werden Hauptabgänge 
identifiziert und als strukturierte Daten zur weiteren Verwendung bereitgestellt.

\paragraph{Performanceprobleme:}  
Die parallele Ausführung von OCR, Kantenerkennung und Clustering führte zu temporären 
Leistungseinbrüchen.

\textbf{Lösung:}  
Die Verwendung eines reduzierten Kamerastreams mit 320 x 320 px, die Auslagerung 
der Bildverarbeitung in einen eigenen Thread sowie gezielte Optimierungen 
(z.\,B. Region-of-Interest, Filterbedingungen) konnten stabile 20 FPS 
sicherstellen.

\end{document}
